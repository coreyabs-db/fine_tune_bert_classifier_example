# The main job for fine_tune_bert_classifier_example.
resources:
  jobs:
    fine_tune_bert_classifier_example_job:
      name: fine_tune_bert_classifier_example_job

      tags:
        project: ${bundle.name}

      trigger:
        # Run this job every day, exactly one day from the last run; see https://docs.databricks.com/api/workspace/jobs/create#trigger
        periodic:
          interval: 1
          unit: DAYS

      #email_notifications:
      #  on_failure:
      #    - your_email@example.com

      parameters:
      - name: catalog_name
        default: ${var.catalog_name}
      - name: schema_name
        default: ${var.schema_name}
      - name: hugging_face_id
        default: google-bert/bert-base-cased

      tasks:
        - task_key: load_docs
          job_cluster_key: extract_load_transform_cluster
          notebook_task:
            notebook_path: ../tasks/load_docs.ipynb
            base_parameters:
              hf_datasets_cache: ${var.volume_root}/yelp_cache_dir/

        - task_key: preprocess_docs
          job_cluster_key: extract_load_transform_cluster
          notebook_task:
            notebook_path: ../tasks/preprocess_docs.ipynb
            base_parameters:
              hf_datasets_cache: ${var.volume_root}/yelp_cache_dir/
          depends_on:
            - task_key: load_docs

        - task_key: prepare_data
          job_cluster_key: extract_load_transform_cluster
          notebook_task:
            notebook_path: ../tasks/prepare_data.ipynb
            base_parameters:
              data_dir: ${var.volume_root}/${bundle.name}/yelp_reviews
          depends_on:
            - task_key: preprocess_docs

        - task_key: train_model
          job_cluster_key: training_cluster
          notebook_task:
            notebook_path: ../tasks/train_model.ipynb
            base_parameters:
              data_dir: ${var.volume_root}/${bundle.name}/yelp_reviews
              experiment_name: ${resources.experiments.classifier_experiment.name}
              ray_collect_log_to_path: ${var.volume_root}/${bundle.name}/ray_logs
              ray_results_dir: ${var.volume_root}/${bundle.name}/ray_results
              hugging_face_id: google-bert/bert-base-cased
              model_name: ${resources.registered_models.yelp_review_classifier.name}
              model_alias: champion
          libraries:
            - pypi:
                package: psutil==7.0.0
            - pypi:
                package: pynvml==12.0.0
          depends_on:
            - task_key: prepare_data

        - task_key: batch_inference
          job_cluster_key: inference_cluster
          notebook_task:
            notebook_path: ../tasks/batch_inference.ipynb
            base_parameters:
              data_dir: ${var.volume_root}/${bundle.name}/yelp_reviews
              experiment_name: ${resources.experiments.classifier_experiment.name}
              ray_collect_log_to_path: ${var.volume_root}/${bundle.name}/ray_logs
              model_name: ${resources.registered_models.yelp_review_classifier.name}
              model_alias: champion
          depends_on:
            - task_key: train_model


      job_clusters:
        - job_cluster_key: extract_load_transform_cluster
          new_cluster:
            spark_version: 16.4.x-cpu-ml-scala2.13
            node_type_id: rd-fleet.xlarge
            data_security_mode: SINGLE_USER
            autoscale:
              min_workers: 4
              max_workers: 4
            aws_attributes:
              first_on_demand: 1
              availability: SPOT_WITH_FALLBACK

        - job_cluster_key: training_cluster
          new_cluster:
            spark_version: 16.4.x-gpu-ml-scala2.13
            node_type_id: g5.12xlarge
            driver_node_type_id: g4dn.xlarge
            data_security_mode: SINGLE_USER
            autoscale:
              min_workers: 2
              max_workers: 2
            spark_conf:
              spark.task.resource.gpu.amount: "0"
            spark_env_vars:
              MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING: true
              MLFLOW_REGISTRY_URI: databricks-uc
              MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR: false
            aws_attributes:
              availability: ON_DEMAND

        - job_cluster_key: inference_cluster
          new_cluster:
            spark_version: 16.4.x-gpu-ml-scala2.13
            node_type_id: g4dn.2xlarge
            data_security_mode: SINGLE_USER
            autoscale:
              min_workers: 8
              max_workers: 8
            spark_env_vars:
              MLFLOW_REGISTRY_URI: "databricks-uc"
              MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR: false
            aws_attributes:
              first_on_demand: 1
              availability: SPOT_WITH_FALLBACK
