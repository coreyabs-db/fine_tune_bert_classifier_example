{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a7887e7-d1a8-4a20-b6f3-a8fb1512d0d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Train the model\n",
    "\n",
    "This task trains the model using DDP using \n",
    "[Ray on Databricks](https://docs.databricks.com/aws/en/machine-learning/ray/).\n",
    "\n",
    "It demonstrates multi-node, multi-GPU training and model logging using a \n",
    "HuggingFace trainer wrapped in Ray train. For hyperparameter sweeps, you \n",
    "can further wrap the Ray trainer with Ray tune and run that in a similar \n",
    "way over the cluster, with the potential for multiple parallel runs if needed.\n",
    "\n",
    "Aside from Ray train, there is also the option to use TorchDistributor to \n",
    "distribute the training over a Spark cluster. Likewise, there are other \n",
    "mechanisms for the trainer and data loader as well, such as using Mosaic \n",
    "Composer and Streaming Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45b5ec30-7c4f-4c98-88b5-f9e97260b5fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports and setup"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from functools import partial\n",
    "from itertools import batched\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "import mlflow.transformers\n",
    "from mlflow.utils.databricks_utils import get_databricks_env_vars\n",
    "from mlflow.pyfunc import PythonModel\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from ray.util.spark import setup_ray_cluster\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.train import ScalingConfig, RunConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "\n",
    "import ray.train.huggingface.transformers\n",
    "from ray.data.context import DataContext\n",
    "\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TextClassificationPipeline,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    "    pipeline\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import os\n",
    "\n",
    "DataContext.get_current().enable_progress_bars = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ee31a45-6e41-406e-9e59-93cef359392d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Task parameters"
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"catalog_name\", \"\")\n",
    "dbutils.widgets.text(\"schema_name\", \"\")\n",
    "dbutils.widgets.text(\"data_dir\", \"\")\n",
    "dbutils.widgets.text(\"experiment_name\", \"\")\n",
    "dbutils.widgets.text(\"ray_results_dir\", \"\")\n",
    "dbutils.widgets.text(\"hugging_face_id\", \"\")\n",
    "dbutils.widgets.text(\"ray_collect_log_to_path\", \"\")\n",
    "\n",
    "catalog_name = dbutils.widgets.get(\"catalog_name\")\n",
    "schema_name = dbutils.widgets.get(\"schema_name\")\n",
    "data_dir = dbutils.widgets.get(\"data_dir\")\n",
    "experiment_name = dbutils.widgets.get(\"experiment_name\")\n",
    "ray_results_dir = dbutils.widgets.get(\"ray_results_dir\")\n",
    "hugging_face_id = dbutils.widgets.get(\"hugging_face_id\")\n",
    "ray_collect_log_to_path = dbutils.widgets.get(\"ray_collect_log_to_path\")\n",
    "\n",
    "\n",
    "assert catalog_name, \"catalog_name is required\"\n",
    "assert schema_name, \"schema_name is required\"\n",
    "assert data_dir, \"data_dir is required\"\n",
    "assert experiment_name, \"experiment_name is required\"\n",
    "assert ray_results_dir, \"ray_results_dir is required\"\n",
    "assert hugging_face_id, \"hugging_face_id is required\"\n",
    "assert ray_collect_log_to_path, \"ray_collect_log_to_path is required\"\n",
    "\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "source_table_name = \"yelp_reviews_silver\"\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "working_dir = \"/local_disk0/tmp/hf_fine_tuning_example\"\n",
    "os.makedirs(working_dir, exist_ok=True)\n",
    "os.chdir(working_dir)\n",
    "\n",
    "os.makedirs(ray_results_dir, exist_ok=True)\n",
    "\n",
    "notebook_context = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "databricks_host = spark.conf.get(\"spark.databricks.workspaceUrl\")\n",
    "databricks_token = notebook_context.apiToken().get()\n",
    "# run_config_storage_path = \"/local_disk0/tmp/ray_results\"\n",
    "\n",
    "cluster_profile = spark.conf.get(\"spark.databricks.cluster.profile\", \"multiNode\")\n",
    "\n",
    "print(f\"catalog_name: {catalog_name}\")\n",
    "print(f\"schema_name: {schema_name}\")\n",
    "print(f\"data_dir: {data_dir}\")\n",
    "print(f\"experiment_name: {experiment_name}\")\n",
    "print(f\"source_table_name: {source_table_name}\")\n",
    "print(f\"hugging_face_id: {hugging_face_id}\")\n",
    "print(f\"splits: {splits}\")\n",
    "print(f\"working_dir: {working_dir}\")\n",
    "print(f\"databricks_host: {databricks_host}\")\n",
    "print(f\"databricks_token: ****************\")\n",
    "print(f\"ray_results_dir: {ray_results_dir}\")\n",
    "print(f\"cluster_profile: {cluster_profile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebf65e37-c183-45d7-b1b6-6b8e1c93b265",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Initialize Ray"
    }
   },
   "outputs": [],
   "source": [
    "# We will use the OSS Ray on Databricks option for distributing our training\n",
    "# over multiple GPU's and multiple nodes in this case. To do so, we first initialize\n",
    "# Ray over the cluster. If we are on a single node, we just call ray.init, but \n",
    "# on multinode we call setup_ray_cluster so it starts on all required nodes.\n",
    "if not ray.is_initialized():\n",
    "\n",
    "    if cluster_profile == \"singleNode\":\n",
    "\n",
    "        # Setting dashboard host to 0.0.0.0 allows us to access the Ray dashboard \n",
    "        # from the driver proxy port. In multi-node clusters this is already handled.\n",
    "        if not ray.is_initialized():\n",
    "            ray.init(dashboard_host=\"0.0.0.0\", dashboard_port=8265)\n",
    "        \n",
    "    else:\n",
    "        max_worker_nodes = 2 # Maximum number of worker nodes that can be used by Ray\n",
    "        min_worker_nodes = 2 # Minimum number of worker nodes that will be used by Ray\n",
    "        num_cpus_worker_node = 32 # Using half of the available CPUs for Ray; the other half can be occupied by Spark\n",
    "        num_gpus_worker_node = 4 # set to 1 so that Ray worker node can use 1 GPU. set to 0 will disallow Ray worker to use GPU.  0 # Set to 0 because if we've set spark.task.resource.gpu.amount to 0 on the cluster, Ray will still grab all the GPUs on the worker nodes\n",
    "        num_cpus_head_node = 4 # Using half the CPUs on the main node\n",
    "        num_gpus_head_node = 0 # Using all the GPUs on the main node\n",
    "\n",
    "        setup_ray_cluster(\n",
    "            max_worker_nodes=max_worker_nodes,\n",
    "            min_worker_nodes=min_worker_nodes,\n",
    "            num_cpus_per_node=num_cpus_worker_node,\n",
    "            num_gpus_per_node=num_gpus_worker_node,\n",
    "            num_cpus_head_node=num_cpus_head_node,\n",
    "            num_gpus_head_node=num_gpus_head_node,\n",
    "            collect_log_to_path=ray_collect_log_to_path\n",
    "        )\n",
    "\n",
    "        ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21dfe82d-470e-4125-a9d8-a19a8980b86b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Prepare datasets"
    }
   },
   "outputs": [],
   "source": [
    "train_path = os.path.join(data_dir, \"train.parquet\")\n",
    "test_path = os.path.join(data_dir, \"test.parquet\")\n",
    "\n",
    "full_train_ds = ray.data.read_parquet(train_path)\n",
    "train_ds, val_ds = full_train_ds.train_test_split(test_size=50000, shuffle=True, seed=42)\n",
    "\n",
    "# We load the test set here to show where to load it, but in the run below\n",
    "# we don't actually use it yet. You would add a final eval on this or do \n",
    "# a separate eval run as part of the deployment job. Skipping for simplicity\n",
    "# and since its not the primary focus here.\n",
    "test_ds = ray.data.read_parquet(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8010acf-13e0-43e3-86c8-c790b9346308",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Helper classes and functions"
    }
   },
   "outputs": [],
   "source": [
    "class CustomMLflowCallback(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Simple HuggingFace training callback for logging to MLflow.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, run_id: str = None, node_id: str = None):\n",
    "        super().__init__()\n",
    "        self.run_id = run_id\n",
    "        self.node_id = node_id\n",
    "        self.run = None\n",
    "\n",
    "    def on_train_begin(self, args, state, control, **kwargs):\n",
    "        # Mostly all the logging happens from global rank 0, but for multi-node \n",
    "        # system metrics collection we can also start the run on each local rank 0.\n",
    "        if state.is_local_process_zero:\n",
    "            mlflow.config.set_system_metrics_node_id(self.node_id)\n",
    "            self.run = mlflow.start_run(run_id=self.run_id)\n",
    "        if state.is_world_process_zero:\n",
    "            mlflow.log_params(vars(args))\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if state.is_world_process_zero:\n",
    "            if logs:\n",
    "                metrics = {k: v for k, v in logs.items() if isinstance(v, (float, int))}\n",
    "                mlflow.log_metrics(metrics, step=state.global_step)\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if state.is_world_process_zero:\n",
    "            if metrics:\n",
    "                mlflow.log_metrics({k: v for k, v in metrics.items() if isinstance(v, (float, int))}, step=state.global_step)\n",
    "\n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        if state.is_world_process_zero:\n",
    "            mlflow.log_artifacts(args.output_dir, artifact_path=\"checkpoints\")\n",
    "\n",
    "    def on_train_end(self, args, state, control, **kwargs):\n",
    "        if state.is_local_process_zero:\n",
    "            mlflow.end_run()\n",
    "\n",
    "\n",
    "class ReviewClassifierModel(PythonModel):\n",
    "    \"\"\"\n",
    "    Custom MLflow PythonModel class for pre and post processing logic, batching,\n",
    "    and ensuring tokenization is correct.\n",
    "    \"\"\"\n",
    "\n",
    "    def load_context(self, context):\n",
    "        tokenizer_dir = context.artifacts[\"tokenizer_dir\"]\n",
    "        model_dir = context.artifacts[\"model_dir\"]\n",
    "        self.batch_size = context.model_config.get(\"batch_size\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "        self.model.eval()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.max_length = self.model.config.max_position_embeddings\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        texts = model_input[\"text\"].tolist()        \n",
    "        results = []\n",
    "        for batch in batched(texts, self.batch_size):\n",
    "            inputs = self.tokenizer(\n",
    "                batch,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "            with torch.inference_mode():\n",
    "                outputs = self.model(**inputs)\n",
    "                probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "            id2label = self.model.config.id2label\n",
    "            for sample_scores in probs:\n",
    "                top_idx = int(sample_scores.argmax())\n",
    "                results.append({\n",
    "                    \"label\": id2label[top_idx],\n",
    "                    \"score\": float(sample_scores[top_idx])\n",
    "                })\n",
    "        return results\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Transform our incoming pre-tokenized batches according to our model's needs.\n",
    "    \"\"\"\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    lengths = [len(x) for x in input_ids]\n",
    "    max_length = max(lengths)\n",
    "    pad_lengths = [max_length - x for x in lengths]\n",
    "    padding = [np.zeros(x, dtype=np.int32) for x in pad_lengths]\n",
    "    padded = [np.concatenate([x, [0] * y]) for x, y in zip(input_ids, padding)]\n",
    "    attention_mask = [[1] * x + [0] * y for x, y in zip(lengths, pad_lengths)]\n",
    "    batch[\"input_ids\"] = torch.tensor(np.stack(padded))\n",
    "    batch[\"attention_mask\"] = torch.tensor(np.stack(attention_mask))\n",
    "    batch[\"labels\"] = torch.tensor(batch[\"label\"])\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(np.stack(padded)),\n",
    "        \"attention_mask\": torch.tensor(np.stack(attention_mask)),\n",
    "        \"labels\": torch.tensor(batch[\"label\"], dtype=torch.long)\n",
    "    }\n",
    "\n",
    "\n",
    "# Collect the local MLflow credentials so that our Ray train function\n",
    "# can close over them for accessing the Databricks managed MLflow instance.\n",
    "mlflow_db_creds = get_databricks_env_vars(\"databricks\")\n",
    "\n",
    "def train_func(config):\n",
    "    \"\"\"\n",
    "    Train a model using the Ray Train API.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import mlflow\n",
    "\n",
    "    # Unpack the Ray train config object.\n",
    "    batch_size = config[\"batch_size\"]\n",
    "    hugging_face_name = config[\"hugging_face_name\"]\n",
    "    eval_steps = config[\"eval_steps\"]\n",
    "    max_steps = config[\"max_steps\"]\n",
    "    experiment_name = config[\"experiment_name\"]\n",
    "    run_id = config[\"run_id\"]\n",
    "\n",
    "    # Compute the ID to use for system metrics collection in MLflow.\n",
    "    node_rank = ray.train.get_context().get_node_rank()\n",
    "    node_id = f\"node-{node_rank}\"\n",
    "\n",
    "    # Use the credentials to set our configured experiment and prepare for logging.\n",
    "    os.environ.update(mlflow_db_creds)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    train_shard = ray.train.get_dataset_shard(\"train\")\n",
    "    val_shard = ray.train.get_dataset_shard(\"val\")\n",
    "\n",
    "    train_iter_ds = train_shard.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "    val_iter_ds = val_shard.iter_torch_batches(batch_size=batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        hugging_face_name, num_labels=5)\n",
    "    \n",
    "    metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        # convert the logits to their predicted class\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    # Hugging Face Trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"yelp_review_classifier\",\n",
    "        logging_strategy=\"steps\",\n",
    "        logging_steps=1,\n",
    "        logging_first_step=True,\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=eval_steps,\n",
    "        save_strategy=\"epoch\",\n",
    "        report_to=\"none\",\n",
    "        max_steps=max_steps,\n",
    "        disable_tqdm=True\n",
    "    )\n",
    "\n",
    "    mlflow_callback = CustomMLflowCallback(\n",
    "        run_id=run_id,\n",
    "        node_id=node_id\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_iter_ds,\n",
    "        eval_dataset=val_iter_ds,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[mlflow_callback]\n",
    "    )\n",
    "\n",
    "    callback = ray.train.huggingface.transformers.RayTrainReportCallback()\n",
    "    trainer.add_callback(callback)\n",
    "\n",
    "    trainer = ray.train.huggingface.transformers.prepare_trainer(trainer)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef70995a-b7c7-41a6-8bd2-e71d544b85a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Fit the model"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    # We would likely move even more of these parameters to task parameters so they're \n",
    "    # externally configurable (e.g., # steps, batch sizes, etc...). Setting here for simplicity.\n",
    "    ray_trainer = TorchTrainer(\n",
    "        train_func,\n",
    "        train_loop_config={\n",
    "            \"batch_size\": 8,\n",
    "            \"hugging_face_name\": \"google-bert/bert-base-cased\",\n",
    "            \"eval_steps\": 25,\n",
    "            \"max_steps\": 50,\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"run_id\": run.info.run_id\n",
    "        },\n",
    "        scaling_config=ScalingConfig(\n",
    "            num_workers=4,\n",
    "            use_gpu=True\n",
    "        ),\n",
    "        run_config=RunConfig(\n",
    "            storage_path=ray_results_dir\n",
    "        ),\n",
    "        datasets={\n",
    "            \"train\": train_ds,\n",
    "            \"val\": val_ds\n",
    "        },\n",
    "        # [4a] For multi-node clusters, configure persistent storage that is\n",
    "        # accessible across all worker nodes\n",
    "        # run_config=ray.train.RunConfig(storage_path=\"s3://...\"),\n",
    "    )\n",
    "\n",
    "    # To do a hyperparameter sweep, you would instead take the Trainer and pass\n",
    "    # it to Ray tune and use that to do a fit. Other than that it is pretty similar.\n",
    "    result: ray.train.Result = ray_trainer.fit()\n",
    "\n",
    "    # Grab the best checkpoint we saw during the run and log it to MLflow,\n",
    "    # along with the tokenizer (even though we pretokenized the results, at inference\n",
    "    # we want the logged model to handle tokenization).\n",
    "    best_checkpoint = result.get_best_checkpoint(metric=\"eval_accuracy\", mode=\"max\")\n",
    "    tokenizer_dir = os.path.join(best_checkpoint.path, \"tokenizer\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(hugging_face_id)\n",
    "    tokenizer.save_pretrained(tokenizer_dir)\n",
    "    model_dir = os.path.join(best_checkpoint.path, \"checkpoint\")\n",
    "\n",
    "    input_example = pd.DataFrame({\"text\": [\"A positive example sentence.\"]})\n",
    "    output_example = pd.DataFrame({\"label\": [\"LABEL_4\"], \"score\": [0.9]})\n",
    "    signature = infer_signature(input_example, output_example)\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=ReviewClassifierModel(),\n",
    "        artifacts={\n",
    "            \"model_dir\": model_dir,\n",
    "            \"tokenizer_dir\": tokenizer_dir\n",
    "        },\n",
    "        input_example=input_example,\n",
    "        signature=signature,\n",
    "        pip_requirements=[\n",
    "            f\"torch=={torch.__version__}\",\n",
    "            f\"transformers=={transformers.__version__}\",\n",
    "            f\"mlflow=={mlflow.__version__}\"\n",
    "        ],\n",
    "        model_config={\n",
    "            \"batch_size\": 32\n",
    "        }\n",
    "    )\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5011751679409674,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "train_model",
   "widgets": {
    "catalog_name": {
     "currentValue": "users",
     "nuid": "a8993e8b-df7c-41da-86eb-3ab50a761ba7",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "catalog_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "data_dir": {
     "currentValue": "/Volumes/users/corey_abshire/fine_tune_bert_classifier_example/yelp_reviews",
     "nuid": "14bee700-1622-4e80-b5b1-6b5238972149",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "data_dir",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "data_dir",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "experiment_name": {
     "currentValue": "/Users/corey.abshire@databricks.com/[dev corey_abshire] fine_tune_bert_classifier_example",
     "nuid": "a97ff607-c717-4df1-9bd3-456e1effffc2",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "experiment_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "experiment_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "hugging_face_id": {
     "currentValue": "google-bert/bert-base-cased",
     "nuid": "1e52730b-8531-4a32-a378-96b0b1b99a60",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "hugging_face_id",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "hugging_face_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "ray_collect_log_to_path": {
     "currentValue": "/Volumes/users/corey_abshire/fine_tune_bert_classifier_example/ray_logs",
     "nuid": "c685f970-6260-4817-82f5-8838ebb6f4cd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "ray_collect_log_to_path",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "ray_collect_log_to_path",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "ray_results_dir": {
     "currentValue": "/Volumes/users/corey_abshire/fine_tune_bert_classifier_example/ray_results",
     "nuid": "0ed23f85-4976-4f55-8814-b5e31a827064",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "ray_results_dir",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "ray_results_dir",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "schema_name": {
     "currentValue": "corey_abshire",
     "nuid": "1af25933-2be5-45c3-be6a-b149b3d55039",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "schema_name",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "schema_name",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "colab": {
   "provenance": []
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
